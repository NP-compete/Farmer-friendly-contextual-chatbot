{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "97rifHR2dyNQ"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 247,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5903,
     "status": "ok",
     "timestamp": 1521399223612,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "vr8ayZRJdaiF",
    "outputId": "e34bee1e-fa67-49ef-815b-03996549804f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflearn\n",
      "  Downloading tflearn-0.3.2.tar.gz (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 2.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn)\n",
      "Building wheels for collected packages: tflearn\n",
      "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/06/72/0478c938ca315c6fddcce8233b80ec91a115ce4496a27e8c90\n",
      "Successfully built tflearn\n",
      "Installing collected packages: tflearn\n",
      "Successfully installed tflearn-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45099,
     "status": "ok",
     "timestamp": 1521399395009,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "clhQq6b8dq6l",
    "outputId": "a72b53a4-d814-4f6e-bba6-18bf8da2d3b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n98XZIVmgyDY"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EZGdflk0dyNW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('drive/Colab Notebooks/chatbot/intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 70,
     "output_extras": [
      {},
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3346,
     "status": "ok",
     "timestamp": 1521400421389,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "eHqXQt8HiAbx",
    "outputId": "b8cc6921-b96a-47be-f0d7-e96ef3ed8758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rLhPWTc_dyNc"
   },
   "outputs": [],
   "source": [
    "words=[]\n",
    "documents=[]\n",
    "classes=[]\n",
    "ignore_words=['?']\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "     # tokenize each word in the sentence\n",
    "         w=nltk.word_tokenize(pattern)\n",
    "     # add to our words list\n",
    "         words.extend(w)\n",
    "    # add to documents in our corpus\n",
    "         documents.append((w, intent['tag']))\n",
    "     # add to our classes list\n",
    "         if intent['tag'] not in classes:\n",
    "             classes.append(intent['tag'])\n",
    "        \n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words=[stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words=sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes=sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1732,
     "status": "ok",
     "timestamp": 1521400435326,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "6qrJABUmdyNl",
    "outputId": "88ab0643-0abc-4cfd-8435-6274cfd9f50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 documents [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Namaste'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['TELL', 'ME', 'ABOUT', 'TAKING', 'SOIL', 'SAMPLE'], 'Soil Testing'), (['How', 'to', 'take', 'soil', 'sample', '?'], 'Soil Testing'), (['What', 'is', 'the', 'technique', 'used', 'in', 'taking', 'soil', 'sample'], 'Soil Testing'), (['TELL', 'ME', 'SOMETHING', 'ABOUT', 'NUTRIENT', 'MANAGEMENT', '?'], 'Nutrient Management'), (['What', 'are', 'some', 'ways', 'to', 'improve', 'nutrients', 'in', 'soil'], 'Nutrient Management'), (['How', 'to', 'manage', 'nutrients'], 'Nutrient Management'), (['TELL', 'ME', 'HOW', 'TO', 'CONTROL', 'INSECT', 'IN', 'WHEAT'], 'Plant Protection'), (['What', 'are', 'some', 'ways', 'to', 'control', 'insects', 'in', 'wheat'], 'Plant Protection'), (['GIVE', 'ME', 'SOME', 'INFORMATION', 'ON', 'SUBSIDIES'], 'Subsidy'), (['What', 'are', 'some', 'various', 'subsidy', 'data', '?'], 'Subsidy'), (['Farm', 'pond'], 'farm pond'), (['Solar', 'plant'], 'solar plant'), (['Pipe', 'line'], 'pipe line')]\n",
      "10 classes ['Nutrient Management', 'Plant Protection', 'Soil Testing', 'Subsidy', 'farm pond', 'goodbye', 'greeting', 'pipe line', 'solar plant', 'thanks']\n",
      "52 unique stemmed words [\"'s\", 'about', 'anyon', 'ar', 'bye', 'control', 'dat', 'day', 'farm', 'giv', 'good', 'goodby', 'hello', 'help', 'hi', 'how', 'improv', 'in', 'inform', 'insect', 'is', 'lat', 'lin', 'man', 'me', 'namast', 'nutry', 'on', 'pip', 'plant', 'pond', 'sampl', 'see', 'soil', 'sol', 'som', 'someth', 'subsidy', 'tak', 'techn', 'tel', 'thank', 'that', 'the', 'ther', 'to', 'us', 'vary', 'way', 'what', 'whe', 'you']\n"
     ]
    }
   ],
   "source": [
    "print (len(documents), \"documents\",documents)\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pxmnwORmdyNv"
   },
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training=[]\n",
    "output=[]\n",
    "\n",
    "# create an empty array for our output\n",
    "output_empty=[0]*len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    bag=[]\n",
    "     # list of tokenized words for the pattern\n",
    "    pattern_words=doc[0]\n",
    "    pattern_words=[stemmer.stem(word.lower()) for word in pattern_words]\n",
    "     # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "        \n",
    "     # output is a '0' for each tag and '1' for current tag\n",
    "    output_row=list(output_empty)\n",
    "    output_row[classes.index(doc[1])]=1\n",
    "    \n",
    "    training.append([bag,output_row])\n",
    "    \n",
    "# shuffle our features and turn into np.array.\n",
    "random.shuffle(training)\n",
    "training=np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 123,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1521400525438,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "ooE5alqwdyNy",
    "outputId": "e5179af7-6ddb-427e-b00f-dd8a6024e7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.78752\u001b[0m\u001b[0m | time: 0.014s\n",
      "| Adam | epoch: 1000 | loss: 0.78752 - acc: 0.8998 -- iter: 24/25\n",
      "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.71449\u001b[0m\u001b[0m | time: 0.019s\n",
      "| Adam | epoch: 1000 | loss: 0.71449 - acc: 0.9098 -- iter: 25/25\n",
      "--\n",
      "INFO:tensorflow:/content/drive/Colab Notebooks/chatbot/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save('drive/Colab Notebooks/chatbot/model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BeUq74ISdyN5"
   },
   "outputs": [],
   "source": [
    "# save all of our data structures\n",
    "import pickle\n",
    "pickle.dump({'words':words,'classes':classes,'train_x':train_x,'train_y':train_y},open('drive/Colab Notebooks/chatbot/training_data','wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "b1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
