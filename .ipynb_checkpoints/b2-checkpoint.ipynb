{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K0Sq6aU0eXrc"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer=LancasterStemmer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "output_extras": [
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5487,
     "status": "ok",
     "timestamp": 1521481572604,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "zZPBqpjAXiZE",
    "outputId": "6585bbff-304e-4d0c-ddcc-d98e7a112a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflearn\n",
      "  Downloading tflearn-0.3.2.tar.gz (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 3.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn)\n",
      "Building wheels for collected packages: tflearn\n",
      "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/06/72/0478c938ca315c6fddcce8233b80ec91a115ce4496a27e8c90\n",
      "Successfully built tflearn\n",
      "Installing collected packages: tflearn\n",
      "Successfully installed tflearn-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 109,
     "output_extras": [
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19397,
     "status": "ok",
     "timestamp": 1521481699377,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "GSbPYIpKjH87",
    "outputId": "1ac72517-f0a2-4105-c51e-7596933e443c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zNZd3a0qYQdD"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q2Bd_jWEeXrq"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "data=pickle.load(open('drive/Google Notebooks/chatbot/training_data','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NrJB7gPheXrx"
   },
   "outputs": [],
   "source": [
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K5Kiz9NDeXr2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('drive/Google Notebooks/chatbot/intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 109,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2849,
     "status": "ok",
     "timestamp": 1521481786328,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "MkP00hOOeXr7",
    "outputId": "f489cc7f-934f-40a9-af53-835c4439834b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from /content/drive/Colab Notebooks/chatbot/model.tflearn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# load our saved model\n",
    "model.load('drive/Google Notebooks/chatbot/model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "20BJNhxUeXsC"
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer().stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G8MuHXg9eXsH"
   },
   "outputs": [],
   "source": [
    "error_thresh=0.25\n",
    "def classify(sentence):\n",
    "     # generate probabilities from the model\n",
    "    results=model.predict([bow(sentence,words)])[0]\n",
    "     # filter out predictions below a threshold\n",
    "    results=[[i,r] for i,r in enumerate(results) if r>error_thresh]\n",
    "     # sort by strength of probability\n",
    "    results.sort(key=lambda x:x[1],reverse=True)\n",
    "    return_list=[]\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]],r[1]))\n",
    "         # return tuple of intent and probability\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mWq2JtYCeXsM"
   },
   "outputs": [],
   "source": [
    "context={}\n",
    "def response(sentence,user_id='123',show_details=False):\n",
    "    results=classify(sentence)\n",
    "     # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "         # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                 # find a tag matching the first result\n",
    "                    if i['tag'] == results[0][0]:\n",
    "                         # set context for this intent if necessary\n",
    "                        if 'context_set' in i:\n",
    "                            if show_details: print('context',i['context_set'])\n",
    "                            context[user_id]=i['context_set']\n",
    "                            \n",
    "                        # check if this intent is contextual and applies to this user's conversation\n",
    "                        if not 'context_filter' in i or (user_id in context and 'context_filter' in i and i['context_filter']==context[user_id]):\n",
    "                            if show_details: print('tag:', i['tag'])\n",
    "                            # a random response from the intent\n",
    "                            return random.choice(i['responses'])\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1521482066271,
     "user": {
      "displayName": "Gaurav Agarwal",
      "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
      "userId": "102008482759980640526"
     },
     "user_tz": -330
    },
    "id": "qIXvrbcTeXsR",
    "outputId": "49cf08be-a2a1-4720-bf3e-7a4da27ed7be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPRAY OF ZINK SULPHATE 5 GRAM +UREA 10 GRAM PER LITER WATER'"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response('tell me about wheat protection')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "b2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
